{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/StaticArrays.ji for module StaticArrays.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/RecipesBase.ji for module RecipesBase.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/ColorTypes.ji for module ColorTypes.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/PlotUtils.ji for module PlotUtils.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/PlotThemes.ji for module PlotThemes.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/Showoff.ji for module Showoff.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/NaNMath.ji for module NaNMath.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/Measures.ji for module Measures.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/PyPlot.ji for module PyPlot.\n",
      "\u001b[39m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Plots.PyPlotBackend()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "#gr()\n",
    "pyplot()\n",
    "#plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Table choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is all about finding patterns in data, so it is very reasonble to start with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 10.1\n",
       " 19.9\n",
       " 30.1\n",
       " 40.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some Data (try your own)\n",
    "x = [5,6.5,7,8]\n",
    "y = [10.1, 19.9, 30.1, 40.3]\n",
    "# plot(x,y,\n",
    "#     label=\"Y\", line=(7,:green), marker=(10,0.8,:red), xlims=(0,10), ylims=(0,50),\n",
    "#     xlabel=\"X\",ylabel=\"Y\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1. Just a matrix please. (No labels, no extras, simple.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×2 Array{Float64,2}:\n",
       " 5.0  10.1\n",
       " 6.5  19.9\n",
       " 7.0  30.1\n",
       " 8.0  40.3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = [x y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2. Data Frames: Inspired by the R universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/DataFrames.ji for module DataFrames.\n",
      "\u001b[39m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>X</th><th>Y</th></tr></thead><tbody><tr><th>1</th><td>5.0</td><td>10.1</td></tr><tr><th>2</th><td>6.5</td><td>19.9</td></tr><tr><th>3</th><td>7.0</td><td>30.1</td></tr><tr><th>4</th><td>8.0</td><td>40.3</td></tr></tbody></table>"
      ],
      "text/plain": [
       "4×2 DataFrames.DataFrame\n",
       "│ Row │ X   │ Y    │\n",
       "├─────┼─────┼──────┤\n",
       "│ 1   │ 5.0 │ 10.1 │\n",
       "│ 2   │ 6.5 │ 19.9 │\n",
       "│ 3   │ 7.0 │ 30.1 │\n",
       "│ 4   │ 8.0 │ 40.3 │"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames\n",
    "data2 = DataFrame(X=x,Y=y) # Upper Case X and Y are labels (not data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element DataArrays.DataArray{Float64,1}:\n",
       " 5.0\n",
       " 6.5\n",
       " 7.0\n",
       " 8.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/NullableArrays.ji for module NullableArrays.\n",
      "\u001b[39mWARNING: Method definition ==(Base.Nullable{S}, Base.Nullable{T}) in module Base at nullable.jl:238 overwritten in module NullableArrays at /Users/edelman/.julia/v0.6/NullableArrays/src/operators.jl:99.\n",
      "WARNING: Method definition ==(Base.Nullable{S}, Base.Nullable{T}) in module Base at nullable.jl:238 overwritten in module NullableArrays at /Users/edelman/.julia/v0.6/NullableArrays/src/operators.jl:99.\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/CSV.ji for module CSV.\n",
      "\u001b[39mWARNING: Method definition ==(Base.Nullable{S}, Base.Nullable{T}) in module Base at nullable.jl:238 overwritten in module NullableArrays at /Users/edelman/.julia/v0.6/NullableArrays/src/operators.jl:99.\n",
      "WARNING: Method definition ==(Base.Nullable{S}, Base.Nullable{T}) in module Base at nullable.jl:238 overwritten in module NullableArrays at /Users/edelman/.julia/v0.6/NullableArrays/src/operators.jl:99.\n",
      "WARNING: Method definition ==(Base.Nullable{S}, Base.Nullable{T}) in module Base at nullable.jl:238 overwritten in module NullableArrays at /Users/edelman/.julia/v0.6/NullableArrays/src/operators.jl:99.\n",
      "WARNING: Method definition ==(Base.Nullable{S}, Base.Nullable{T}) in module Base at nullable.jl:238 overwritten in module NullableArrays at /Users/edelman/.julia/v0.6/NullableArrays/src/operators.jl:99.\n",
      "WARNING: Compat.AsyncCondition is deprecated, use Base.AsyncCondition instead.\n",
      "  likely near /Users/edelman/.julia/v0.6/IJulia/src/kernel.jl:31\n",
      "WARNING: Compat.AsyncCondition is deprecated, use Base.AsyncCondition instead.\n",
      "  likely near /Users/edelman/.julia/v0.6/IJulia/src/kernel.jl:31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CSV.Sink(    CSV.Options:\n",
       "        delim: ','\n",
       "        quotechar: '\"'\n",
       "        escapechar: '\\\\'\n",
       "        null: \"\"\n",
       "        dateformat: dateformat\"yyyy-mm-dd\", IOBuffer(data=UInt8[...], readable=true, writable=true, seekable=true, append=false, size=0, maxsize=Inf, ptr=1, mark=-1), \"data.csv\", 8, true, String[\"X\", \"Y\"], false)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pkg.add(\"CSV\")\n",
    "using CSV\n",
    "CSV.write(\"data.csv\", data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"X\",\"Y\"\n",
      "5.0,10.1\n",
      "6.5,19.9\n",
      "7.0,30.1\n",
      "8.0,40.3\n"
     ]
    }
   ],
   "source": [
    ";cat data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3. Indexed Tables (Treat data like array indices, knows type information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X   │ Y\n",
       "────┼─────\n",
       "5.0 │ 10.1\n",
       "6.5 │ 19.9\n",
       "7.0 │ 30.1\n",
       "8.0 │ 40.3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pkg.add(\"IndexedTables\")\n",
    "using  IndexedTables.Table\n",
    "using IndexedTables\n",
    "data3 = Table(Columns(X=x),Columns(Y=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Y = 19.9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3[6.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{DataType,1}:\n",
       " Array{Float64,2}                                                                                                                                                                                                                                 \n",
       " DataFrames.DataFrame                                                                                                                                                                                                                             \n",
       " IndexedTables.IndexedTable{NamedTuples._NT_Y{Float64},Tuple{Float64},IndexedTables.Columns{NamedTuples._NT_X{Float64},NamedTuples._NT_X{Array{Float64,1}}},IndexedTables.Columns{NamedTuples._NT_Y{Float64},NamedTuples._NT_Y{Array{Float64,1}}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof.([data1,data2,data3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.4. JuliaDB (Lots of bells and whistles, many files, parallelism, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPrecompiling module JuliaDB.\n",
      "\u001b[39m\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mModule IndexedTables with uuid 559715602718134 is missing from the cache.\n",
      "This may mean module IndexedTables does not support precompilation but is imported by a module that does.\u001b[39m\n",
      "\u001b[1m\u001b[91mERROR: \u001b[39m\u001b[22mLoadError: \u001b[91mDeclaring __precompile__(false) is not allowed in files that are being precompiled.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] "
     ]
    }
   ],
   "source": [
    "#Pkg.add(\"JuliaDB\")\n",
    "using JuliaDB:DTable\n",
    "using JuliaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: distribute not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: distribute not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "data4 = distribute(data3, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data5 = loadfiles([\"data.csv\"], usecache=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeof(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data4[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select(data4,1=>i->i≥7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter(t->(t[1]>30),data4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.5 IterableTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#using IterableTables, DataTables, TypedTables # haven't investigated  much but looks very nice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Simple Line Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[So why is it called \"Regression\" anyway?](http://blog.minitab.com/blog/statistics-and-quality-data-analysis/so-why-is-it-called-regression-anyway) Dalton's original meaning not quite what it means today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.1 Linear Regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-42.45733333333333, 10.197333333333333)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, w =  linreg(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot()\n",
    "plot(x,y,\n",
    "    label=\"Y\", line=(4,:blue), marker=(3,0.8,:blue), xlims=(0,10), ylims=(0,50),\n",
    "    xlabel=\"X\",ylabel=\"Y\")\n",
    "plot!(x->w*x+b,xlims=(minimum(x)-.5,maximum(x)+.5), line=(4,:red), label=\"best fit line\")\n",
    "plot!(x->w*x+b, x ,marker=(3,0.8,:red), label=\"\" )\n",
    "for i = 1:length(x)\n",
    "    plot!([x[i],x[i]],[y[i],w*x[i]+b],line=(4,:green))\n",
    "end\n",
    "plot!(legend=:topleft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically equivalent Approaches <br>\n",
    "B.2 Linear Algebra Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = [ones(x) x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A'A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A\\y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(A'A)\\A'y  # normal equations usually not recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q,r = qr(A)\n",
    "r\\(q'y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[length(x) sum(x); sum(x) x⋅x] \\ [ sum(y) ; x⋅y ] # (A'A)\\A'y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.3 Basic Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = cov(x,y)/var(x) # same as (x.-mean(x))⋅(y.-mean(y))/sum(abs2,x.-mean(x))\n",
    "b = mean(y)-w*mean(x)\n",
    "b,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@which linreg(x,y) # essentially uses the above formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.4 optimization  (think machine learning) via the package optim.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Optim   # Julia all the way down\n",
    "loss(bw) = sum(abs2,bw[2]*x.+bw[1]-y) # uglyish\n",
    "optimize(loss,[0.0,0.0]).minimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.5 optimization with the package JuMP <br>\n",
    "Note not every julia function can be in @objective or @NLobjective\n",
    "but that would be the goal. See  [linear and quadratic objective Jump Notes](http://www.juliaopt.org/JuMP.jl/0.18/refexpr.html)  and [Nonlinear Jump Notes](http://www.juliaopt.org/JuMP.jl/0.18/nlp.html#syntax-notes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"Ipopt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using JuMP, Ipopt\n",
    "n = length(x)\n",
    "m = Model(solver=IpoptSolver(print_level=0))\n",
    "@variable(m,w)\n",
    "@variable(m,b)\n",
    "@objective(m, Min, sum((w*x[i]+b-y[i])^2 for i in 1:n))\n",
    "#@objective(m, Min,   sum(abs2,  w*x+b-y))\n",
    "solve(m)\n",
    "println( \" b = \", getvalue(b), \"w = \", getvalue(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.6 Generalized Linear Models <br>\n",
    "the very fancy statistical thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"GLM\")\n",
    "using GLM # Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm(@formula(Y~X), data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines above are obviously b and w\n",
    "We assume at the start X is known without error, b,w,σ are unknown and\n",
    "the real Y is distributed like  b+w*X+$\\sigma *$randn(),\n",
    "and the Y we have are samples from this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under these assumptions, if we fit many times, the b and w would be normal, with these predicted standard deviations.\n",
    "\n",
    "The third column is just the ratio of column 1 to column 2 , thus normalizing the situation to a standard normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the probability column is less than .05, we can reject the hypothesis that the intercept/slope is 0 at the 5 percent signficance level. What does this mean? It means we feel pretty good about our intercept and slope. If the probability is higher than .05 we can not reject the null hypothesis, meaning that we feel 0 for the intercept/slope could have been possible. In particular a 0 slope says that the dependent variable is not really statistically dependent after all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss(w,b,i) =(w*x[i]+b-y[i])^2  # loss due to point i\n",
    "Dloss(w,b,i) = 2*(w*x[i]+b-y[i])*[x[i];1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w,b = 0.0, 0.0\n",
    "for t=1:100000\n",
    "    η = .002  # there seems to be an art to picking these steplengths\n",
    "    i = rand(1:4)\n",
    "    d = Dloss(w,b,i)\n",
    "    w -= η * d[1]\n",
    "    b -= η * d[2]  \n",
    "end\n",
    " println(b,\" \",w)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss(w,b,i) =(w*χ[i]+b-y[i])^2  # loss due to point i\n",
    "Dloss(w,b,i) = 2*(w*χ[i]+b-y[i])*[χ[i];1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "μ = mean(x)\n",
    "σ = std(x)\n",
    "χ = (x-μ)/σ\n",
    "\n",
    "w,b = 0.0, 0.0\n",
    "for t=1:100000\n",
    "    η = .01  # there seems to be an art to picking these steplengths\n",
    "    i = rand(1:4)\n",
    "    d = Dloss(w,b,i)\n",
    "     w -= η * d[1]\n",
    "     b -= η * d[2] \n",
    "    ## instead fancy update rules like Adam ??\n",
    "   \n",
    "end\n",
    " println(b-w*μ/σ,\" \",w/σ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  D. KNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"Knet\")\n",
    "using Knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(w,x) = w[2]*x .+ w[1]\n",
    "loss(w,x,y) = sum(abs2, y - predict(w,x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lossgradient = grad(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train(w, data; lr=.1)\n",
    "    p=1\n",
    "    for (x,y) in data\n",
    "        println(\"This is pass $p\")\n",
    "        p+=1\n",
    "        dw = lossgradient(w, x, y)\n",
    "        for i in 1:length(w)\n",
    "            w[i] -= lr * dw[i]\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train([0.0,0.0],zip(x,y),lr=.01) # not enough data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [(x[i],y[i]) for i=1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train2(w, data; lr=.1)\n",
    "       for t in 1:10000\n",
    "          \n",
    "        (x,y) = data[rand(1:4)]\n",
    "        dw = lossgradient(w, x, y)\n",
    "            for i=1:length(w)\n",
    "            w[i] -= lr * dw[i]\n",
    "            #update(w, lossgradient(w,x,y), adam())\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2([0.0;0.0],data,lr=.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/edelman/.julia/lib/v0.6/TensorFlow.ji for module TensorFlow.\n",
      "\u001b[39m\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mLoading a new version of TensorFlow.jl for the first time. This initial load can take around 5 minutes as code is precompiled; subsequent usage will only take a few seconds.\u001b[39m\n",
      "2017-10-10 07:22:53.779166: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-10-10 07:22:53.779194: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Session(Ptr{Void} @0x00000001211cee50)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pkg.add(\"TensorFlow\")\n",
    "using TensorFlow\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFlow.Variables.Variable{Float64}(<Tensor node_2:1 shape=() dtype=Float64>, <Tensor node_2/Assign:1 shape=unknown dtype=Float64>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = TensorFlow.Variable(randn())\n",
    "b = TensorFlow.Variable(randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33m.+ is no longer a function object; use broadcast(+, ...) instead\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1m(::Base.##712#713)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Tensor{Float64}, ::TensorFlow.Variables.Variable{Float64}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:346\u001b[22m\u001b[22m\n",
      " [3] \u001b[1m(::TensorFlow.###8#9#11{Base.##712#713})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::TensorFlow.Tensor{Float64}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/edelman/.julia/v0.6/TensorFlow/src/meta.jl:67\u001b[22m\u001b[22m\n",
      " [4] \u001b[1m(::TensorFlow.##8#10)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Tensor{Float64}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/edelman/.julia/v0.6/TensorFlow/src/meta.jl:67\u001b[22m\u001b[22m\n",
      " [5] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m\n",
      " [6] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/edelman/.julia/v0.6/Compat/src/Compat.jl:464\u001b[22m\u001b[22m\n",
      " [7] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/edelman/.julia/v0.6/IJulia/src/execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [8] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/edelman/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [9] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[3], in expression starting on line 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Tensor Y_obs:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf X = placeholder(Float32)\n",
    "@tf Y = multiply(X,W).+b\n",
    "@tf Y_obs = placeholder(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor reduce:1 shape=unknown dtype=Float64>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf Loss=sum( (Y.-Y_obs).^2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Group:1 shape=unknown dtype=Any>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = TensorFlow.train.GradientDescentOptimizer(1e-3)\n",
    "minimizer = TensorFlow.train.minimize(optimizer, Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: x not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: x not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m./In[6]:3\u001b[22m\u001b[22m [inlined]",
      " [2] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m./<missing>:?\u001b[22m\u001b[22m",
      " [3] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "run(session, global_variables_initializer())\n",
    "for i in 1:20000\n",
    "    run(session, minimizer, Dict(X=>x, Y_obs=>y))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " -1.32189 \n",
       "  0.907986"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(session, [b, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session=Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf X=placeholder(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf W=get_variable([], Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "@tf b=get_variable([], Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf Y=X.*W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf Y_obs=placeholder(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf Loss=reduce_sum((Y.-Y_obs).^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer=train.GradientDescentOptimizer(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minimizer=train.minimize(optimizer, Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run(session, global_variables_initializer())\n",
    "for i in 1:20000\n",
    "    run(session, minimizer, Dict(X=>[5,6.5,7,8], Y_obs=>[10.1,19.9,30.1,40.3]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run(session, [b, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating METADATA...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of Plots...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of Lazy...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of StatPlots...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of CategoricalArrays...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of NNlib...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of IJulia...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of JuliaDB...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of FFTW...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of WeakRefStrings...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of DataStreams...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of RecipesBase...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of Compat...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of TensorFlow...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of ShowItLikeYouBuildIt...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of Flux...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of Parameters...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of Codecs...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of OffsetArrays...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of SpecialFunctions...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of IndexedTables...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating Interact master...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage SpecialFunctions: skipping update (pinned)...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mComputing changes...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading Codecs: v0.3.0 => v0.4.0\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading Compat: v0.32.0 => v0.33.0\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading Flux: v0.3.1 => v0.3.2\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading IJulia: v1.6.1 => v1.6.2\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading IndexedTables: v0.3.2 => v0.3.3\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading JuliaDB: v0.3.1 => v0.3.2\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading Lazy: v0.11.7 => v0.12.0\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading NNlib: v0.1.1 => v0.1.2\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading OffsetArrays: v0.4.1 => v0.4.2\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading Parameters: v0.7.3 => v0.8.0\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading Plots: v0.12.4 => v0.13.1\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading RecipesBase: v0.2.2 => v0.2.3\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading ShowItLikeYouBuildIt: v0.1.1 => v0.2.0\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading StatPlots: v0.5.0 => v0.5.1\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading TensorFlow: v0.7.2 => v0.7.3\n",
      "\u001b[39m\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mThe following packages have been updated but were already imported:\n",
      "- Compat\n",
      "- IJulia\n",
      "- Plots\n",
      "- RecipesBase\n",
      "- TensorFlow\n",
      "Restart Julia to use the updated versions.\u001b[39m\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Conda\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Homebrew\n",
      "\u001b[39mWarning: Already linked: /Users/edelman/.julia/v0.6/Homebrew/deps/usr/Cellar/fontconfig/2.12.1_2\n",
      "Warning: Already linked: /Users/edelman/.julia/v0.6/Homebrew/deps/usr/Cellar/gdk-pixbuf/2.36.11\n",
      "Warning: Already linked: /Users/edelman/.julia/v0.6/Homebrew/deps/usr/Cellar/glib/2.54.1\n",
      "Warning: Already linked: /Users/edelman/.julia/v0.6/Homebrew/deps/usr/Cellar/gobject-introspection/1.54.1\n",
      "Warning: Already linked: /Users/edelman/.julia/v0.6/Homebrew/deps/usr/Cellar/gtk+3/3.22.24\n",
      "Warning: Already linked: /Users/edelman/.julia/v0.6/Homebrew/deps/usr/Cellar/imagemagick@6/6.9.7-3\n",
      "Warning: Already linked: /Users/edelman/.julia/v0.6/Homebrew/deps/usr/Cellar/librsvg/2.40.19\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding MbedTLS\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding ZMQ\n",
      "\u001b[39mWARNING: Compat.KERNEL is deprecated.\n",
      "  likely near /Users/edelman/.julia/v0.6/ZMQ/deps/build.jl:35\n",
      "WARNING: Compat.KERNEL is deprecated.\n",
      "  likely near /Users/edelman/.julia/v0.6/ZMQ/deps/build.jl:35\n",
      "in can_use at /Users/edelman/.julia/v0.6/Homebrew/src/bindeps_integration.jl\n",
      "WARNING: Compat.KERNEL is deprecated.\n",
      "  likely near /Users/edelman/.julia/v0.6/ZMQ/deps/build.jl:35\n",
      "in package_available at /Users/edelman/.julia/v0.6/Homebrew/src/bindeps_integration.jl\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding IJulia\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mInstalling Jupyter via the Conda package.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mFound Jupyter version 4.3.0: /Users/edelman/.julia/v0.6/Conda/deps/usr/bin/jupyter\n",
      "\u001b[39m  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12309  100 12309    0     0  82402      0 --:--:-- --:--:-- --:--:-- 82610\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mInstalling Julia kernelspec julia-0.6\n",
      "\u001b[39m[InstallKernelSpec] Removing existing kernelspec in /Users/edelman/Library/Jupyter/kernels/julia-0.6\n",
      "[InstallKernelSpec] Installed kernelspec julia-0.6 in /Users/edelman/Library/Jupyter/kernels/julia-0.6\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Plots\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Rmath\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding Blosc\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding HDF5\n",
      "\u001b[39mWARNING: Compat.KERNEL is deprecated.\n",
      "  likely near /Users/edelman/.julia/v0.6/HDF5/deps/build.jl:40\n",
      "WARNING: Compat.KERNEL is deprecated.\n",
      "  likely near /Users/edelman/.julia/v0.6/HDF5/deps/build.jl:40\n",
      "in can_use at /Users/edelman/.julia/v0.6/Homebrew/src/bindeps_integration.jl\n",
      "WARNING: Compat.KERNEL is deprecated.\n",
      "  likely near /Users/edelman/.julia/v0.6/HDF5/deps/build.jl:40\n",
      "in package_available at /Users/edelman/.julia/v0.6/Homebrew/src/bindeps_integration.jl\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding PyCall\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPyCall is using /Users/edelman/.julia/v0.6/Conda/deps/usr/bin/python (Python 2.7.13) at /Users/edelman/.julia/v0.6/Conda/deps/usr/bin/python, libpython = /Users/edelman/.julia/v0.6/Conda/deps/usr/lib/libpython2.7\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36m/Users/edelman/.julia/v0.6/PyCall/deps/deps.jl has not changed\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36m/Users/edelman/.julia/v0.6/PyCall/deps/PYTHON has not changed\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding TensorFlow\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mBuilding TensorFlow.jl for CPU use only. To enable the GPU, set the TF_USE_GPU environment variable to 1 and rebuild TensorFlow.jl\n",
      "\u001b[39mWarning: 'conda-forge' already in 'channels' list, moving to the top\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 11.3M  100 11.3M    0     0  5768k      0  0:00:02  0:00:02 --:--:-- 5770k\n"
     ]
    }
   ],
   "source": [
    "Pkg.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
